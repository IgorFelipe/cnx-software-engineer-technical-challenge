# ============================================================================# Database Configuration

# EMAIL MAILING SERVICE - ENVIRONMENT CONFIGURATION# PostgreSQL connection string

# ============================================================================# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE?schema=SCHEMA

# Copy this file to .env and fill in your valuesDATABASE_URL="postgresql://postgres:postgres@localhost:5432/email_mailing?schema=public"

# Never commit .env with real secrets to source control!

# ============================================================================# Server Configuration

PORT=3000

# ============================================================================NODE_ENV=development

# DATABASE CONFIGURATION
# ============================================================================
# PostgreSQL connection string
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE?schema=SCHEMA
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/email_mailing?schema=public"

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================
# API server port
PORT=3000

# Node environment (development | production | test)
NODE_ENV=development

# ============================================================================
# AUTHENTICATION API CONFIGURATION
# ============================================================================
# CNX Email Test API authentication endpoint
AUTH_API_URL=https://email-test-api-475816.ue.r.appspot.com/auth/token

# Authentication credentials
AUTH_USERNAME=cnx_test
AUTH_PASSWORD=cnx_password_2025!

# Token renewal window (milliseconds before expiry to trigger renewal)
# Recommended: 300000 (5 minutes) to ensure token never expires during use
TOKEN_RENEWAL_WINDOW_MS=300000

# ============================================================================
# EMAIL API CONFIGURATION
# ============================================================================
# CNX Email Test API base URL
EMAIL_API_URL=https://email-test-api-475816.ue.r.appspot.com

# ============================================================================
# RATE LIMITING CONFIGURATION
# ============================================================================
# Maximum requests per minute (API limit: 6 requests/min = 1 request per 10 seconds)
# After probing: set to 80% of discovered limit for safety margin
# Current: 6 req/min with 1000ms buffer = ~11 seconds between requests
RATE_LIMIT_PER_MINUTE=6

# Worker concurrency (number of parallel email sending workers)
# Keep at 1 for strict rate limiting compliance
# Increase only if API supports concurrent requests
WORKER_CONCURRENCY=1

# ============================================================================
# RETRY POLICY CONFIGURATION
# ============================================================================
# Maximum number of retry attempts before moving to Dead Letter Queue (DLQ)
# Recommended: 3 attempts (initial + 2 retries)
MAX_RETRIES=3

# Base delay for exponential backoff (milliseconds)
# Formula: delay = base * 2^(attempt-1) ± jitter%
# Example with base=1000ms: 1s, 2s, 4s, 8s, 16s, 32s...
RETRY_BASE_DELAY_MS=1000

# Maximum retry delay cap (milliseconds)
# Prevents exponential backoff from becoming unbounded
# Recommended: 300000 (5 minutes)
RETRY_MAX_DELAY_MS=300000

# Jitter percentage for retry delay (0-100)
# Adds randomness to prevent thundering herd: delay ± jitter%
# Recommended: 20 (±20% randomization)
RETRY_JITTER_PERCENT=20

# ============================================================================
# CSV PROCESSING CONFIGURATION
# ============================================================================
# Checkpoint interval (number of lines between progress saves)
# Lower values = more frequent saves = better crash recovery but slower
# Higher values = less overhead but more lines to reprocess after crash
# Recommended: 1000 for large files, 100 for small files
CSV_CHECKPOINT_INTERVAL=1000

# Batch size for database inserts (number of records per batch)
# Larger batches = better performance but higher memory usage
# Recommended: 500 for optimal balance
CSV_BATCH_SIZE=500

# ============================================================================
# EMAIL VALIDATION CONFIGURATION
# ============================================================================
# Enable MX record lookup (DNS validation)
# More accurate but slower (adds ~100-500ms per unique domain)
# Recommended: false for development, true for production
ENABLE_MX_CHECK=false

# Enable disposable email domain detection
# Blocks temporary/throwaway email services
# Recommended: true (minimal performance impact)
ENABLE_DISPOSABLE_CHECK=true

# ============================================================================
# RABBITMQ CONFIGURATION
# ============================================================================
# RabbitMQ connection URL
# Format: amqp://USER:PASSWORD@HOST:PORT
RABBITMQ_URL=amqp://rabbitmq:rabbitmq@localhost:5672

# Worker consumer prefetch count (QoS)
# Number of unacknowledged messages per worker
# Recommended: 1 for strict sequential processing
RABBITMQ_PREFETCH=1

# ============================================================================
# OUTBOX PUBLISHER CONFIGURATION
# ============================================================================
# Poll interval for unpublished outbox messages (milliseconds)
# How often to check database for new messages to publish
# Recommended: 5000 (5 seconds) for near-real-time processing
OUTBOX_POLL_INTERVAL_MS=5000

# Batch size for outbox publishing
# Number of messages to publish per poll cycle
# Recommended: 10 for optimal throughput
OUTBOX_BATCH_SIZE=10

# Maximum publish attempts before marking as failed
# After this many failures, message moves to dead letter
# Recommended: 5 attempts
OUTBOX_MAX_ATTEMPTS=5

# ============================================================================
# CRASH RECOVERY CONFIGURATION
# ============================================================================
# Stale job threshold (milliseconds)
# Jobs in SENDING/PROCESSING status older than this are re-queued on boot
# Recommended: 300000 (5 minutes) - normal processing takes seconds
STALE_SENDING_THRESHOLD_MS=300000

# ============================================================================
# GRACEFUL SHUTDOWN CONFIGURATION
# ============================================================================
# Graceful shutdown timeout (milliseconds)
# How long to wait for queue to drain before forcing shutdown
# Recommended: 30000 (30 seconds)
SHUTDOWN_TIMEOUT_MS=30000

# Force shutdown timeout (milliseconds)
# Maximum time before forcing immediate exit (may leave inconsistent state)
# Recommended: 60000 (60 seconds)
FORCE_SHUTDOWN_TIMEOUT_MS=60000

# ============================================================================
# FAILURE THRESHOLD CONFIGURATION
# ============================================================================
# Failure rate threshold (0.0 - 1.0)
# If this percentage of emails fail, mark entire mailing as failed
# Example: 0.2 = 20% failure rate triggers mailing failure
# Recommended: 0.2 for early detection of systematic issues
FAILURE_THRESHOLD=0.2

# ============================================================================
# LOGGING & OBSERVABILITY CONFIGURATION
# ============================================================================
# Log level (debug | info | warn | error)
# Recommended: info for production, debug for development
LOG_LEVEL=info

# Prometheus metrics port
# Metrics available at http://localhost:METRICS_PORT/metrics
# Recommended: 9100 (standard Prometheus exporter port)
METRICS_PORT=9100

# ============================================================================
# INCREMENTAL ROLLOUT FEATURE FLAGS
# ============================================================================
# Enable/disable Outbox Publisher (publishes messages from outbox to RabbitMQ)
# Set to 'false' to disable publisher during rollout phases
# Recommended: 'true' for production, 'false' for initial migration testing
ENABLE_OUTBOX_PUBLISHER=true

# Enable/disable Worker Consumer (consumes and processes messages from RabbitMQ)
# Set to 'false' to disable consumer during rollout phases
# Recommended: 'true' for production, 'false' for publisher-only testing
ENABLE_WORKER_CONSUMER=true

# Maximum number of consumer replicas (for horizontal scaling)
# Controls how many consumer instances can run in parallel
# Recommended: 1 for canary, increase gradually to 3-5 for production
MAX_CONSUMER_REPLICAS=1

# ============================================================================
# NOTES & BEST PRACTICES
# ============================================================================
# 1. Security:
#    - Never commit .env with real credentials to version control
#    - Use secret managers (AWS Secrets Manager, HashiCorp Vault) in production
#    - Rotate credentials regularly
#
# 2. Rate Limiting:
#    - Run probe-rate-limit.sh to discover actual API limits
#    - Set RATE_LIMIT_PER_MINUTE to 80% of discovered limit
#    - Monitor 429 errors and adjust accordingly
#
# 3. Performance:
#    - Increase WORKER_CONCURRENCY only if API supports it
#    - Larger CSV_BATCH_SIZE improves throughput but uses more memory
#    - Balance CSV_CHECKPOINT_INTERVAL between performance and recovery
#
# 4. Reliability:
#    - Keep MAX_RETRIES at 3 for most cases
#    - Adjust RETRY_MAX_DELAY_MS based on your SLA requirements
#    - Monitor DLQ and investigate permanent failures
#
# 5. Development:
#    - Use docker-compose.yml for local development environment
#    - Run 'docker-compose up -d' to start PostgreSQL + RabbitMQ
#    - See README.md for complete setup instructions
# ============================================================================
